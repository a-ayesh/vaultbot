{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸš€ Repository Setup Guide\n",
    "\n",
    "**Purpose:** Set up and run the server using the backend/start.sh script\n",
    "\n",
    "---\n",
    "\n",
    "## Quick Start\n",
    "\n",
    "1. Build the frontend\n",
    "```bash\n",
    "npm install\n",
    "npm run build\n",
    "```\n",
    "\n",
    "2. Install the python backend dependencies at `backend/requirements.txt`\n",
    "```bash\n",
    "pip install uv\n",
    "uv sync\n",
    "```\n",
    "\n",
    "3. Run the setup script\n",
    "```bash\n",
    "./backend/start.sh\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Note:** The start.sh script will:\n",
    "- Set up Python virtual environment\n",
    "- Install dependencies\n",
    "- Configure environment variables\n",
    "- Start required services\n",
    "\n",
    "**Troubleshooting:**\n",
    "- Ensure you have Python 3.12+ installed\n",
    "- Check file permissions if script fails to execute\n",
    "- Verify all required environment variables are set\n",
    "\n",
    "**Docker Note:** Docker setup is not recommended at this time due to long build times and performance overhead.\n",
    "\n",
    "## Methodology\n",
    "\n",
    "### Base Project Selection\n",
    "We chose [OpenWebUI](https://github.com/open-webui/open-webui) as our foundation because:\n",
    "- Modern, production-ready codebase with active development\n",
    "- Clean architecture with clear separation of concerns\n",
    "- Built-in support for multiple LLM backends\n",
    "- Robust frontend with real-time chat interface\n",
    "- Extensive documentation and community support\n",
    "- Proven scalability in production environments\n",
    "- Easy to extend and customize for our specific needs\n",
    "\n",
    "### Embedding Model Selection\n",
    "We chose `sentence-transformers/all-MiniLM-L6-v2` for text embeddings because:\n",
    "- Lightweight (384 dimensions) with strong performance\n",
    "- Fast inference suitable for real-time queries\n",
    "- Proven track record in semantic search tasks\n",
    "- Lower memory footprint than larger models\n",
    "- Outperforms other models of similar size on MTEB benchmarks\n",
    "- [Highly popular on Hugging Face](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2) with over 1M downloads \n",
    "- The defacto standard for semantic search across a wide range of open source projects\n",
    "\n",
    "### LLM Selection\n",
    "We selected `meta/llama3.2:3b` for RAG Q&A because:\n",
    "- 3B parameters provide good balance of performance and resource usage\n",
    "- Strong performance on instruction following\n",
    "- Efficient inference on consumer hardware\n",
    "- Lower latency than larger models\n",
    "- Cost-effective for deployment\n",
    "- [Top performer on OpenLLM Leaderboard](https://huggingface.co/spaces/open-llm-leaderboard/open_llm_leaderboard#/?params=-1%2C6&official=true) when filtering for <6B official models and sorting for top IFEval score.\n",
    "\n",
    "### Architecture Decisions\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"./images/architecture.png\" style=\"width: 1000px;\">\n",
    "</div>\n",
    "\n",
    "- **RAG Pipeline**: Chose RAG over fine-tuning to leverage existing knowledge while maintaining flexibility\n",
    "- **Vector Store**: Using ChromaDB for fast similarity search and efficient storage\n",
    "- **API Design**: RESTful endpoints for easy integration with frontend\n",
    "- **Caching**: Implemented response caching to reduce LLM calls\n",
    "\n",
    "\n",
    "**Authors:**\n",
    "- Ayesh Ahmad (365966)\n",
    "- Farooq Afzal (365793)\n",
    "- Muhammad Faras Siddiqui (365988)\n",
    "\n",
    "**Last Updated:** May 4, 2025\n",
    "**Version:** 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
